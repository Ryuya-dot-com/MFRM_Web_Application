# Many-Facet Rasch Model Shiny App

ブラウザで Many-Facet Rasch Model (MFRM) を推定・可視化できる Shiny アプリです。`brms` の累積リンク混合モデル (CLMM) を用いて各ファセットの事後分布、信頼性指標、残差診断などを一括で確認できます。

## What is MFRM?
Many-Facet Rasch Model は、受験者・課題・評価者・評価観点など複数の「ファセット（facet）」が関与するパフォーマンステストを同時に評価する測定モデルです。英語スピーキングテストを例にすると、受験者が複数の課題（Task）に回答し、複数の評価者（Rater）が「内容」「語彙」「発音」などの観点（Criterion）で 1～5 の評価を付ける状況が想定できます。MFRM では、
- 受験者の能力（話す力）
- 課題の難易度（話しやすさ）
- 評価者の厳しさ／甘さ
- 評価観点ごとのハードル
を同じ尺度上に置き、どの要素がスコアに影響しているかを明らかにします。本アプリはこの考え方をベイズ推定で実装し、事後平均や信頼性指標、Wright マップなどを確認できるようにしています。

英語スピーキングテストの匿名化データセットを想定すると、1 行には「受験者 ID（Person）」「課題名（Task）」「評価者（Rater）」「評価観点（Criterion）」「評定結果（Rating）」が含まれます。`Rating` は 1～5 のような段階性のある順序尺度で、1 が「十分でない」、5 が「優れている」といった意味を持つケースを想定しています。同じ受験者が複数課題に回答し、複数の評価者が複数観点で採点するため、1 人の受験者について複数行が記録されるロングフォーマットになります。

背景知識として、MFRM は順序ロジスティック回帰（累積ロジットモデル）を多ファセット化したものと捉えられます。本アプリが採用している累積リンク混合モデル（CLMM）は、例えばカテゴリ $k$ 以下を観測する条件付き確率を

![formula](https://latex.codecogs.com/svg.latex?\Pr(Y_{ijrc}\leq%20k)=\tau_k-(\theta_i-\delta_j-\rho_r-\kappa_c))

のように表現します。ここで $Y_{i j r c}$ は受験者 $i$ が課題 $j$ 、評価者 $r$ 、観点 $c$ で得た評定、 $\tau_k$ はカテゴリ境界（閾値）、 $\theta_i$ は受験者能力、 $\delta_j$ は課題難易度、 $\rho_r$ は評価者の厳しさ、 $\kappa_c$ は観点固有のハードルです。単一の順序ロジスティック回帰では固定効果で表す部分を、MFRM ではファセットごとのランダム効果として推定することで、ベイズ的な事後分布や信頼性指標を得る点が特徴です。

## Overview
- ペーストまたはファイルアップロードでデータを読み込み、UI 上で列マッピングとモデリング設定を実施
- `brms` によるベイズ推定：link (logit/probit/cauchit/log-log) と threshold (flexible/symmetric/equidistant) を切り替え可能
- 出力タブ：データプレビュー、モデル要約、ファセット推定、信頼性・分離指数、フィット統計、残差 PCA、Wright マップ、閾値分析、記述統計
- 各指標は `gt` テーブルや `plotly` でインタラクティブに表示。CSV/TSV テンプレートと解析結果のダウンロードが可能。

## App Workflow
- **Step 1 Data Input**: テンプレに貼り付けるかファイルを選択。必要なら 1 行追加やリセットが可能。
- **Step 2 Data Configuration**: ヘッダー有無と区切り文字を調整し、`Load Data` でプレビューを更新。
- **Step 3 Column Mapping**: Person/Response 列と解析したいファセットを選択。単一レベルのファセットは通知付きで自動除外されます。
- **Step 4 Model Configuration**: リンク関数と閾値構造を指定。
- **Step 5 Analysis**: `Run MFRM Analysis` を押すとベイズ推定が走り、各タブに結果が反映されます。

## Outputs & Downloads
- **Model Summary**: 収束診断 (R-hat, ESS, 発散) とモデリング設定を確認。
- **Facet Parameters**: 各ファセット水準の事後平均と 66%/95% 信頼区間、Rasch 符号規約で表示。
- **Reliability & Separation**: 観測 SD、RMSE、Adjusted SD、Reliability、Separation、Strata を事後分布から推定し、解釈ガイド付きで提示。
- **Fit Diagnostics**: Infit/Outfit MNSQ と ZSTD、残差プロット、PCA スクリープロット、ロード図、バイプロットなどで単一性をチェック。
- **Wright Map & Thresholds**: 受験者分布とファセット難易度、カテゴリ閾値、カテゴリー確率曲線を可視化。
- **Downloads**: 解析サマリー、ファセット推定、信頼性指標、フィット統計、閾値表を CSV で保存可能。

## Tips
- 解析の安定化には 30 観測以上、ファセット各水準 3 水準以上、カテゴリ利用の偏りが小さいデータが望ましいです。
- Person ID や Rating に欠損がある行は自動除去されます。除外件数は通知に表示されるため、必要に応じてデータを点検してください。
- `pacman::p_load()` が不足パッケージを自動導入しますが、企業ネットワーク等で失敗する場合は事前に個別インストールしてください。
- 重いモデル（多ファセット・高カテゴリ）の場合、MCMC に時間がかかります。`chains` や `iter` 設定を変更したい場合は `app.R` 下部の `brm()` 呼び出しを調整できます。

上記の流れで、MFRM の概要指標から詳細な残差診断までを一貫して確認できます。

## Quick Start
1. R (推奨 4.x) を用意し、必要パッケージをインストールします。
   ```r
   install.packages("pacman")
   pacman::p_load(
     shiny, shinythemes, shinyjs, tidyverse, brms, ggrepel, plotly, DT, gt,
     psych, ggridges, tidybayes, posterior, loo, performance, bayestestR,
     effectsize, parameters, emmeans
   )
   ```
2. 本リポジトリを作業ディレクトリに設定し、アプリを起動します。
   ```r
   shiny::runApp("app.R")
   # 必要に応じてホストやポートを指定: 
   # shiny::runApp('app.R', host = '0.0.0.0', port = 8080)
   ```
3. ブラウザが自動で開かない場合は、コンソールに表示される URL をコピーしてアクセスしてください。

## Data Checklist
- ファイル形式：CSV、TSV、区切りテキスト（カンマ/セミコロン/タブ）。Excel の場合は「名前を付けて保存」→「CSV UTF-8」がお勧めです。
- データ構造：**ロングフォーマット**が必須です。1 行に「受験者 × 課題 × 評価者 × 観点 × 評価」が揃っている必要があります。列が横に並ぶワイド形式の場合は、Excel の「Power Query」や `tidyr::pivot_longer()` で縦持ちに変換してください。
- 必須列：
  - `Person` (受験者 ID)
  - `Rating` または `Response` (序数カテゴリ。最低 2 カテゴリ、推奨 3 以上)
- 推奨列：`Task`、`Rater`、`Criterion` などのファセット（1 つ以上）。空欄は "Missing" に再符号化されます。
- サンプルデータ：左ペインの「Download sample TSV/CSV」から `data/sample_data.csv` を基にした欠損なしデータを保存できます。貼り付け用テンプレも UI に常備しています。

## Step 1: Data Input を詳しく
`Step 1: Data Input` では **コピー＆ペースト** と **ファイルアップロード** の 2 通りの方法が選べます。慣れていない方は次の手順を参考にしてください。

### A. コピー＆ペーストで読み込む
1. サンプルテンプレートの文字列（画面に表示されている `Person	Task	...` 形式）をコピーして Excel などに貼り付け、必要な行を編集します。
2. 最終的なデータがロングフォーマット（1 行 = 1 評価）になっていることを確認します。列の順番はテンプレートと同じでなくても構いませんが、タブやカンマで区切られた表形式である必要があります。
3. 編集したテーブル全体をコピーし、アプリのテキストエリアに貼り付けます。
4. `Append row` ボタンを使うと 1 行ずつ追加できます。列数が足りない場合は自動で空欄が補われます。
5. 次の `Step 2` でヘッダーや区切り文字を確認し、`Load Data` を押してプレビューを表示します。

### B. ファイルをアップロードして読み込む
1. データを CSV/TSV で保存します。Excel の場合は「ファイル > 名前を付けて保存 > CSV UTF-8」を選び、ファイル名が半角英数字になっているか確認します。
2. データがロングフォーマットであるか確認します。列が横に並ぶ場合は、Power Query の「列のピボット解除」や `tidyr::pivot_longer()` で縦持ちに変換し、`Person`, `Task`, `Rater`, `Criterion`, `Rating` のような列にまとめます。
3. `Step 1: Data Input` で `Upload file (CSV/TSV)` を選択し、`Choose file` ボタンから保存したファイルを指定します。
4. ファイルを選択したら `Step 2` に進み、ヘッダーと区切り文字の設定を調整してから `Load Data` を押します。

## Step 2: Data Configuration を詳しく
`Step 2` では読み込んだ表の形式をアプリに伝えます。設定が正しくないと列名が乱れたり、値がずれる原因になります。

- **Header チェックボックス**: テーブルの 1 行目が列名であれば ON のままにします（CSV/TSV では通常 ON）。OFF にすると 1 行目もデータとみなされ、列名は自動的に `V1`, `V2`, ... に置き換わります。コピー＆ペーストで見出し行を削除してしまった場合などは OFF にしてください。
- **Separator ラジオボタン**: データの区切り文字に合わせて選択します。
  - CSV（カンマ区切り）→ `Comma`
  - Excel でセミコロン区切りになったファイル → `Semicolon`
  - テンプレを貼り付けた場合や TSV ファイル → `Tab`
- **Load Data ボタン**: 設定を確認したら押します。右側の `Data Preview` に先頭 50 行が表示され、`Data Structure` で列名・型・欠損数を確認できます。期待どおりに表示されない場合は `Separator` や `Header` を変更して再度 `Load Data` を押してください。

### CSV をアップロードしたときの設定例
1. `Step 1` で `Upload file (CSV/TSV)` を選択し、`Choose file` から `my_speaking_scores.csv` を指定。
2. `Step 2` に移動し、`Header` が ON になっていることを確認（Excel で列名を入れて保存した場合は ON が正解）。
3. `Separator` を `Comma` に設定。日本語 Excel で自動的にセミコロン区切りになっている場合はファイルの中身を確認し、必要なら `Semicolon` を選ぶ。
4. `Load Data` をクリック。プレビューで `Person`, `Task`, `Rater`, `Criterion`, `Rating` などの列が正しく読み込まれているかを確認。
5. 列がずれていたり文字化けしている場合は、ファイルを UTF-8 で保存し直したり、区切り設定を再確認してやり直します。

## Step 3: Column Mapping を詳しく
`Step 3` では、読み込んだ列を MFRM の各ファセットに対応づけます。ここでの指定が分析結果の基準になるため、列名だけでなく「誰を表す列か」をイメージしながら選びます。

- **Person ID Column**: 受験者を識別する列を選びます。`Person`, `受験者`, `CandidateID`, `student_id`, `学習者` など名称は自由ですが、同じ受験者には同じ値が入る必要があります。数値でも文字列でも構いません。
- **Response/Rating Column**: 評価の段階（例：1～5、Beginner/Intermediate/Advanced など）が入った列を選びます。順序尺度であることが前提なので、カテゴリが 2 つ以下になっていないか確認してください。
- **Facet Columns**: 課題（Task）、評価者（Rater）、評価観点（Criterion）、授業グループなど、分析したい軸を複数選択します。`Select Facet Columns` でチェックを入れると該当列がモデルに含まれます。水準が 1 つだけの列は自動的に除外され、通知が表示されます。

`Person ID` の列を迷う場合は「分析レポートを誰に返したいか」を考えると分かりやすいです。受験者個人の成績を比較したいなら受験者 ID、クラス単位で集計したいなら学級 ID といった具合に、最も認識しやすい単位を選択してください。

## Step 4: Model Configuration を詳しく
`Step 4` では、順序尺度をどのようにモデル化するかを指定します。リンク関数と閾値構造の組み合わせによって、カテゴリの境界をどのように仮定するかが決まります。

### Link Function (リンク関数) とは？
順序ロジスティック回帰では、あるカテゴリ以下になる確率をロジットやプロビットといった「リンク関数」で変換して直線的に扱います。例えば `Logit` を選ぶと、「カテゴリ $k$ 以下になる確率 $p$」を

![formula](https://latex.codecogs.com/svg.latex?\mathrm{logit}(p)=\log\left(\tfrac{p}{1-p}\right))

のように対数オッズへ変換し、受験者能力や課題難易度との線形関係で説明します。`Logit` は 0.5 までは緩やか、0 や 1 に近づくと急峻に変化する S 字カーブを描くため、序数データの扱いには一般的で、アプリの既定値になっています。

他の選択肢として、`Probit`（正規分布に基づくカーブ）、`Cauchit`（裾の重いカーブ）、`Log-log`（上側に重みを置くカーブ）が用意されています。たとえば、極端な上位カテゴリが出やすいデータで「上位への到達」を強調したい場合に `Log-log` を試す、といった使い分けが可能です。まずは `Logit` のままで結果を確認し、必要に応じて他のリンクを試してみるのがおすすめです。

### Threshold Structure (閾値構造) とは？
順序カテゴリには、カテゴリ 1 と 2 の境界、2 と 3 の境界…といった「閾値」(threshold) が存在します。MFRM/CLMM では、これらの閾値をどのように配置するかを `Threshold Structure` で指定します。

- **Flexible (既定)**: すべての閾値を自由に推定します。カテゴリ間の間隔が不均一でもデータに合わせて調整できるため、まずはこの設定を推奨します。
- **Symmetric**: 境界が平均値を挟んで対称になると仮定します。例えば 1～5 の場合、中央カテゴリに向かって左右対称な位置に閾値が置かれます。
- **Equidistant**: 隣り合う閾値の間隔を等間隔に固定します。例として、カテゴリ 1～5 なら「1.0, 2.0, 3.0, 4.0」のように一定の差で配置するイメージです。尺度が均等であるという強い仮定が置かれます。

`Flexible` を選ぶと、1→2 の移行が難しいが 3→4 は容易といった偏りがあってもモデルが吸収できます。例として、「発音」観点では 4 から 5 に上がるのが難しい（高い閾値）、一方で「内容」観点では 2 から 3 に上がるのが難しい、といった差が推定結果として確認できます。対して `Equidistant` を選ぶと、「どの観点でもカテゴリ間の距離は同じ」という前提になるため、評価基準を人為的に揃えたい場合の感度分析に向いています。

リンク関数と閾値構造は後から変更して再解析できます。既定の `Logit` × `Flexible` でフィットを確認し、必要に応じて他の組み合わせを試してみてください。

## Beginner Walkthrough
初めての方向けに、Excel で小さなデータを作成して読み込む例を示します。

1. **データを準備する**
   - Excel で `Person`, `Task`, `Rater`, `Criterion`, `Rating` の見出しを作成。
   - `Person` には P01, P02 ... のような ID、`Rating` には 1〜5 など序数カテゴリを入力。
   - 行はロングフォーマット（各評価を 1 行）で作成する。例：同じ受験者が 2 課題を受けたら 2 行、評価者 3 人なら 3 行追加されるイメージ。
   - ファイルを `CSV UTF-8 (コンマ区切り)` で保存。空欄があれば「Missing」扱いになるので、可能なら入力しておく。
2. **アプリを起動する**
   - `shiny::runApp("app.R")` を実行。ブラウザが開かないときは、R コンソールに表示されたリンクをコピーしてブラウザに貼り付ける。
3. **データを読み込む**
   - コピー＆ペーストを使う場合はテキストエリアに貼り付け、アップロードを使う場合は CSV を選択。
   - `Step 2: Data Configuration` で `Header` と `Separator` を設定し、`Load Data` を押す。
   - 右ペインの `Data Preview` と `Data Structure` で列名と値が正しく読めているかを確認する。
4. **列をマッピングする**
   - `Step 3: Column Mapping` で `Person ID Column` に `Person`、`Response/Rating Column` に `Rating` を選ぶ。
   - `Select Facet Columns` で `Task`, `Rater`, `Criterion` にチェックを入れる。1 つしか水準がない列は自動的に除外され、画面上部に警告が出る。
5. **モデル設定をする**
   - `Step 4: Model Configuration` でリンク関数や閾値構造を選択。迷った場合は既定の `Logit` × `Flexible` で開始。
6. **解析を実行する**
   - `Step 5: Analysis` 内の `Run MFRM Analysis` をクリック。処理中はプログレスバーと通知が表示される。
   - 完了後、各タブ (`Model Summary`, `Facet Parameters`, `Reliability & Separation` など) を順に開き、結果を確認。必要に応じて `Download ...` ボタンで CSV を保存。

## Troubleshooting Data Loading
- **列名が読めない**: `Header` を ON にしているか確認。列名が空欄の場合、`Column_1` のように自動でリネームされます。
- **文字化けする**: ファイルを UTF-8 で保存する。Excel であれば「CSV UTF-8」で書き出し、再読み込み前にブラウザをリロード。
- **区切りが合わない**: `Separator` を `Comma`, `Semicolon`, `Tab` から切り替えて再読み込み。
- **空の行・列が多い**: 読み込み後の `Data Structure` で `Missing Values` が多い列を確認し、元データをクリーニング。
- **欠損で行が落ちる**: 解析前に Person や Rating が欠損している行は通知付きで削除される。通知に表示された件数を基に元ファイルを修正する。

## Interpreting Results の読み方
ここから先は、アプリの各タブで得られる指標を順番に確認していきます。`Model Summary` で推定が安定しているかを確かめた後、ファセット推定値、測定精度、フィット統計、次元性、Wright マップと閾値へと進むのがおすすめです。

## Interpreting Results: Model Summary から始める
分析ボタンを押した直後は、まず `Model Summary` タブを確認しましょう。ここには「モデルがきちんと推定できたか」を判断する基本情報がまとまっています。

- **MCMC Convergence Diagnostics**: `Max R-hat` が 1.01 以下、`Divergent Transitions` が 0 であれば、推定の繰り返しが安定しているサインです。色が赤くなったり数値が大きいときは、データの抜けや極端なカテゴリ分布がないかをチェックしましょう。
- **Effective Sample Size (ESS)**: `Min Bulk ESS` や `Min Tail ESS` が低すぎる場合（例：100 未満）、サンプルが十分に混ざっていない可能性があります。データ量を増やしたり、Step 4 の設定をシンプルにして再試行するのが安全です。
- **Model Summary**: 使用したリンク関数 (`Logit` など) や閾値構造 (`Flexible` など)、観測数・チェーン数を一覧できます。ここで想定通りの設定になっているかを再確認しましょう。
- **通知メッセージ**: 解析中に表示された警告（例：欠損の自動除外、カテゴリ不足）も重要な手がかりです。通知を見逃した場合はブラウザ右上のメッセージ履歴を確認してください。

基礎的な診断をクリアできたら、次は `Fixed Effects`（固定効果）と `Random Effects`（ランダム効果）を順番に眺めて、モデルがどのような構造を学習したのかを理解していきます。

### Fixed Effects と Credible Interval の見方
`Fixed Effects` テーブルには、カテゴリ間の境界（閾値）がどの位置にあるかが表示されます。ここで示される `Mean` は「平均的な境界の位置」、`66% CrI` や `95% CrI` は「ほぼこの範囲に収まるだろう」という信頼区間（Credible Interval）を表します。区間が狭いほど推定が安定しており、広いほど不確実性が大きいと理解してください。まずは `Mean` の大小関係を押さえ、区間が極端に広がっている閾値がないかを確認するのが手軽です。

また、閾値の位置は「どの段階の評価を取りやすいか」に影響します。閾値が全体的に高い場合は、上位カテゴリへ到達するには高い潜在能力が必要になるため、全体として厳しい評価になりがちです。逆に、閾値が低いと中位・上位カテゴリが出やすく、評価が甘くなっていないかを疑う指標になります。観点ごとに閾値を比較すると、どの観点で点数が伸びやすい／伸びにくいかが見えてきます。

### Random Effects の読み方
`Random Effects Standard Deviations` は、受験者・課題・評価者・観点といったファセットごとの「ばらつき幅」を示します。`Mean` が大きいほど、そのファセット内での違いが大きい（例：評価者によって採点の厳しさが大きく異なる）ことを意味します。`CrI` の範囲を見ながら、0 に近いかどうかをざっくり判断するとよいでしょう。例えば、`Rater` の区間が 0 から離れていれば「評価者の差が明確にある」、0 に近ければ「評価者間の差は小さい」と解釈できます。

補足として、ここでのランダム効果は「ファセットごとの潜在変数」をモデリングしています。MFRM では受験者能力・課題難易度・評価者の厳しさなどを正規分布のランダム効果として捉え、各水準が母集団からのサンプルであると考えます。そのため、ファセットをランダム効果として扱うことで、未観測の水準にも一般化しやすくなり、事後分布を通じて信頼性や分離指数を推定できるようになります。

正確な数値解釈よりも、どのファセットに大きな変動があるか、どの閾値が極端に離れているかといった“傾向”を掴むことから始めるとスムーズです。

## Interpreting Results: Facet Parameters
`Facet Parameters` タブでは、受験者（Person）、課題（Task）、評価者（Rater）、評価観点（Criterion）などの水準ごとに、どれくらい「能力が高い」「難しい／重い」「厳しい（Severity）」といった傾向があるかを確認できます。テーブルは Rasch 流の符号規約に合わせて表示しており、Person 以外のファセットについては内部で係数の符号を反転させ、値が大きいほど「より難しい／厳しい」方向になります。

- **Person Parameters (Ability)**: `Mean` が大きいほど能力が高く、正の値の受験者は高い評価を得やすい層、負の値は低い評価に偏りがちです。`CrI` が 0 を跨いでいる場合は、平均より高いか低いかの判定が難しいため、他の情報と合わせて解釈します。
- **Task Parameters (Difficulty)**: 値が高い課題ほど難しく、平均的な受験者でも高いカテゴリに到達しづらいことを示します。負の値であれば比較的取り組みやすい課題と解釈できます。例えば `Essay` が正の値、`Presentation` が負の値であれば、エッセイは高得点を取りにくく、プレゼンテーションは取りやすい傾向があると言えます。複数の課題がばらけている方が、低～高能力の受験者を幅広く弁別できて望ましい状態です。
- **Rater Parameters (Severity)**: ここでは実質的に評価者の「厳しさ」を表します。正の値の評価者は厳しめに採点し、負の値の評価者は甘めに採点する傾向があると読めます。名称は `Difficulty` と表示されますが、意味としては Severity（厳しさ）と考えてください。指導上は、評価者同士の 95% 事後区間が大きく重なるほど採点姿勢が揃っていると判断できます。例えば `Rater_B` の区間が `Rater_A` や `Rater_C` とほとんど重なっていれば、評価者間の偏りが小さく安定した採点体制と言えるでしょう。
- **Criterion Parameters (Difficulty)**: 各評価観点のハードルを示します。値が高い観点は高いスコアが付きにくく、低い観点はスコアが伸びやすい傾向を表します。観点ごとの偏りを把握し、評価規準の調整に役立てます。

いずれの表でも、66%・95% 事後区間が広い水準は不確実性が大きく、データを追加したり、コメントベースで補足するなどの対応を検討すると安心です。

## Interpreting Results: Reliability & Separation
`Reliability & Separation` タブでは、各ファセットの測定精度をまとめた指標が表示されます。数値の意味と計算方法は次のとおりです（`ObsSD` などは `Mean` 列で代表値、`66%/95%` 列は事後区間です）。

- **ObsSD (Observed SD)**: 推定されたパラメータ（例：受験者能力）の標準偏差。
式は ![formula](https://latex.codecogs.com/svg.latex?\text{ObsSD}=\sqrt{\text{VarLevel}}\))
値が大きいほど、そのファセット内での違いが大きいことを示します。例：受験者の ObsSD が 2.6 程度であれば、能力が高い人と低い人がバランス良く混在しており、テストが幅広い層をカバーしていると考えられます。逆に 0.4 程度しかない場合は、ほとんどの受験者が似た得点になっているサインです。
- **RMSE (Root Mean Square Error)**: 事後平均からの誤差の二乗平均平方根。
式は ![formula](https://latex.codecogs.com/svg.latex?\text{RMSE}=\sqrt{\frac{1}{n}\sum(\text{Display}-\text{Mean})^2}\))
測定の“揺らぎ”であり、値が小さいほど精度が良いことを表します。例：評価者の RMSE が 0.7 程度なら、採点が平均から少しブレている程度、0.2 なら非常に安定、1.5 なら採点の揺れが大きいと判断できます。
- **AdjSD (Adjusted SD)**: 測定誤差を差し引いた真の標準偏差。
式は ![formula](https://latex.codecogs.com/svg.latex?\text{AdjSD}=\sqrt{\max(\text{VarLevel}-\text{RMSE}^2,0)}\))
ObsSD から RMSE を引いて残る「実力差」の部分です。例：受験者の ObsSD=2.6、RMSE=1.1 なら AdjSD ≈ 2.3 となり、大部分が実力差として説明されます。もし AdjSD がほぼ 0 なら、観測されたばらつきのほとんどが誤差であることを意味します。
- **Reliability**: 信頼性係数（真の分散 / 観測分散）。
式は ![formula](https://latex.codecogs.com/svg.latex?\text{Reliability}=\text{AdjSD}^2/\text{ObsSD}^2\))
0～1 の範囲で、0.8 以上なら測定が安定していると考えられます。例：受験者の信頼性が 0.83 であれば、受験者間の能力差の 83% は実際の差であり、残り 17% が測定誤差と解釈できます。観点の信頼性が 0.35 のように低い場合は、観点間のばらつきが誤差に近く、評価基準の再検討が必要です。
- **Separation**: 真の標準偏差を RMSE で割ったもの。
式は ![formula](https://latex.codecogs.com/svg.latex?\text{Separation}=\text{AdjSD}/\text{RMSE}\))
2 以上なら良好、3 以上なら優れた弁別力です。たとえば Separation=2.0 なら、受験者を誤差込みで 2 グループ程度（高得点群と低得点群）に分けられる精度がある、と直感的に理解できます。課題の Separation が 1.2 と低い場合は、課題間の難易度差よりも誤差が大きいことを意味し、課題設定の見直しを検討します。
- **Strata**: Separation を 0～∞ から 1～∞ の尺度に変換したもの。
式は ![formula](https://latex.codecogs.com/svg.latex?\text{Strata}=(4\times\text{Separation}+1)/3\))
3 以上で「統計的に区別できるレベルが 3 つ以上ある」と解釈できます。例：評価者 Strata が 3.5 なら、厳しさのレベルが少なくとも 3 段階（甘め・標準・厳しめ）に分かれていると考えられます。

これらの指標を並べて見ると、「受験者の能力差は十分大きいが、課題の難易度差は小さい」「評価者は厳しさにばらつきがある」といった診断がしやすくなります。66%・95% 区間が閾値（Reliability 0.8 など）を跨いでいる場合は、確信度が十分でない点に注意しつつ、データやルーブリックの改善に活かしてください。

## Interpreting Results: Fit Statistics（残差プロット）
`Fit Statistics` タブでは、モデルの予測と実際のデータがどれくらい一致しているかを残差（予測値と実測値の差）で確認できます。最初の 4 つのプロットの読み方は次の通りです。

- **Residuals vs Fitted（左上）**: 横軸が予測された値、縦軸が残差です。赤い破線が 0、青い線は loess スムージングです。理想的には残差が 0 の周りにばらつき、青線がほぼ水平になります。もし青線が大きく波打っていれば、特定の予測値で体系的なズレがあるサインです。
- **Q-Q Plot（右上）**: 標準化残差が正規分布に従っているかを確認します。点が赤線に沿って並んでいれば概ね正規性に問題はありません。下側で大きく離れていれば、低いカテゴリで外れ値が多い可能性があります。
- **Histogram + Density（左下）**: 標準化残差のヒストグラムと密度曲線です。山が 0 周辺に左右対称であれば望ましい状態です。歪みや裾野の広がりが目立つ場合は、データの偏りやリンク関数の再検討を考えます。
- **Observed vs Fitted（右下）**: 実測カテゴリ（横軸）と予測カテゴリ（縦軸）の関係です。点が赤い 45 度線に近いほど予測が正確であることを示します。例えば、カテゴリ 3 の点が線から離れていれば、3 点を過大または過小に予測しているかもしれません。

これらのプロットをセットで確認することで、「全体的なズレ」「分布の歪み」「特定カテゴリの偏り」を把握できます。問題が見つかった場合は、データの再確認やリンク関数・閾値構造を変更して再分析するのが有効です。

### Fit 統計量とは
残差プロットに続いて、各ファセットの「Fit 統計量」が表示されます。これは Rasch モデルでよく使われる指標で、実測値がモデルの期待値とどの程度一致しているかを数値化したものです。略語の意味は次の通りです。

- **InfitMSQ**: Information-weighted mean-square。期待値に近いデータ点を重視した平均二乗残差。
- **OutfitMSQ**: Outlier-sensitive mean-square。外れ値（期待値から遠い点）に敏感な平均二乗残差。
- **InfitZSTD / OutfitZSTD**: Infit/Outfit を正規化した Z 値。±2 を超えると要注意。
- **MeanResid / SdResid**: 残差の平均と標準偏差。
- **MaxAbsZ**: InfitZSTD・OutfitZSTD のうち最大の絶対値。

数値が 1 に近ければ予測と実測がよく一致しており、`InfitMSQ` や `OutfitMSQ` が 1.5 を超えると「Underfit（ばらつきが大きすぎ）」、0.5 未満だと「Overfit（変動が小さすぎ）」とみなします。Overfit はデータが“出来すぎ”で、新しいデータでは再現できない可能性を示唆します。Underfit は予測に収まりきらないほど不規則な挙動があるサインで、採点やデータ入力の見直しが必要です。

計算は残差 ![formula](https://latex.codecogs.com/svg.latex?r_i=y_i-\hat{y}_i) を基礎にしており、

![formula](https://latex.codecogs.com/svg.latex?\text{InfitMSQ}=\frac{\sum%20w_i%20r_i^2}{\sum%20w_i}),  
![formula](https://latex.codecogs.com/svg.latex?\text{OutfitMSQ}=\frac{1}{n}\sum%20r_i^2)

のように求めます（![formula](https://latex.codecogs.com/svg.latex?w_i) はカテゴリーの情報量、![formula](https://latex.codecogs.com/svg.latex?n) は観測数）。  

これらを正規化した Z 値は、`app.R` 内の

![formula](https://latex.codecogs.com/svg.latex?Z=\frac{MSQ^{1/3}-\bigl(1-\tfrac{2}{9df}\bigr)}{\sqrt{\tfrac{2}{9df}}})

により算出されます（![formula](https://latex.codecogs.com/svg.latex?df) は自由度）。  

平均残差は  

![formula](https://latex.codecogs.com/svg.latex?\text{MeanResid}=\tfrac{1}{n}\sum%20r_i),  

標準偏差は  

![formula](https://latex.codecogs.com/svg.latex?\text{SdResid}=\sqrt{\tfrac{1}{n-1}\sum(r_i-\text{MeanResid})^2})  

です。`MaxAbsZ` は Infit・Outfit Z の最大絶対値で、最も外れた水準を素早く特定できます。

続いて、同じタブ内には平均二乗統計と Z 統計をまとめた散布図、およびテーブル形式の詳細も用意されています。

- **Mean-square Fit by Facet（上段の散布図）**: 横軸が Infit/Outfit の均一化平均二乗統計 (MSQ)、縦軸にファセットと水準が並びます。記号は下向き三角（0.5 未満）、丸（0.5～1.5）、上向き三角（1.5 超）で、0.5～1.5 が目安の許容範囲です。例：`Project` の Outfit MSQ が 1.8 で上向き三角なら、その課題で予測よりもバラつきが大きいことを示し、設問内容や採点のばらつきを再点検します。
- **Z-standardized Fit（下段の散布図）**: 横軸が Infit ZSTD、縦軸が Outfit ZSTD です。|Z| > 2 の点はダイヤモンド記号で強調され、当該水準が期待から外れている可能性を示します。例えば、`Student_005` が (−3.5, −3.4) に位置していれば、予想より安定しすぎている（過剰適合）状況が考えられるため、データ入力や採点を確認します。正の方向に離れていれば、ばらつきが大きい（過小適合）ことを意味します。

- **Person / Facet Fit Statistics テーブル**: 各水準について件数 `N`、Infit/Outfit MSQ と ZSTD、残差平均 (`MeanResid`) と標準偏差 (`SdResid`)、最大 |Z| などを一覧できます。背景色は MSQ が 0.5 未満（淡い青）または 1.5 超（淡い赤）の行をハイライトしているため、目視で異常を探しやすくなっています。MSQ は 1 が理想で、0.5 未満は「変動が少なすぎ」、1.5 超は「ばらつきが大きすぎ」を意味します。ZSTD は ±2 を超えると要注意域で、表では `MaxAbsZ` 列で最も大きい Z 値を確認できます。これらの数値を見ながら、データ入力ミスや特定水準の挙動（例：ある課題だけ回答が極端に偏る）を調査すると効果的です。

## Interpreting Results: Dimensionality Analysis
`Dimensionality Analysis` タブでは、残差の主成分分析 (PCA) を用いて単一尺度の仮定が妥当かを確認します。主な出力と読み方は以下の通りです。

- **Scree Plot**: 主成分の固有値を並べた折れ線グラフです。赤い破線（固有値 1）より大きい成分が複数あれば、多次元性の兆候があります。固有値 1 を超える成分が 1 つだけで、2 番目以降が急に小さくなるなら、単一尺度の仮定が概ね成立していると考えられます。
- **Eigenvalues Table**: 各主成分の固有値と寄与率（% Variance）を一覧できます。例えば PC1 が 18%、PC2 が 9% 程度に留まるなら、残差の大半はランダムノイズと考えられます。反対に PC1 が 25% を超えたり、PC1 と PC2 の比が 3 未満であれば、多次元性を疑って追加調査を検討します。
- **Loadings Plot**: PC1 に強く寄与している組み合わせ（例：`Rater_B_Task_Project`）を上位 20 件まで表示します。棒グラフが片側に偏っていれば、特定の課題や評価者が同じ方向に残差を引きずっている可能性があります。
- **Biplot**: PC1×PC2 の空間に、距離が大きい項目（課題×評価者×観点の組み合わせ）が表示されます。同じ課題や評価者に関連する点が同じ象限に固まっている場合は、共通の潜在要因（例：特定評価者だけ極端に厳しい）が残差に残っているサインです。
- **Unidimensionality Assessment テーブル**: 固有値や寄与率、1/2 成分比から総合的な結論を提示します。例として「PC1 variance explained」が 15%、「Eigenvalue ratio」が 4.2 であれば「Acceptable unidimensionality」となり、モデルは概ね単一尺度に収まっています。一方、PC1 が 25% 超、比が 3 未満なら「Potential multidimensionality detected」と表示され、ルーブリック構造やデータの偏りを再検討する余地があります。

これらの指標を総合的に見ることで、「評価者グループで特定方向の残差が溜まっている」「課題タイプ別に別の尺度が潜んでいる」といった兆候を早期に把握できます。該当する評価者・課題を別尺度として扱う、またはモデルに追加のファセットを導入するといった修正を検討してください。

残差 PCA は「全体 (Overall)」のほか、`Task` や `Rater` などファセットごとにも実行できます。どちらのアプローチがより適切かについてはまだ十分な研究が蓄積されておらず、状況に応じて双方を比較検討するのが現時点での実務的な対応です。今後の研究でベストプラクティスが整理されることが期待されています。

## Interpreting Results: Wright Map & Thresholds
`Wright Map` と関連する図表は、受験者能力・課題難易度・評価者の厳しさ・カテゴリ閾値を同じ潜在尺度上に重ねて比較できるツールです。ベイズ推定なので、点の両側に 66%（太線）と 95%（細線）の事後区間がつきます。66% CrI は「3 人中 2 人ほどがこの範囲に入る」感覚の短い区間、95% CrI は「20 人中 19 人ほど」が入る長めの区間と捉えるとイメージしやすいでしょう。

- **Wright Map**: 背景の青い帯が受験者能力の分布（山が右に寄ればハイレベル受験者が多い）、各ファセット行の点と線が水準の推定値と区間です。例えば `Task:Project` の点が受験者分布の中心より左（低い位置）にあれば、「今回の受験者にとって比較的易しい課題だった」と解釈できます。反対に `Task:Essay` が右側なら、エッセイは難しめです。`Rater` 行で `Rater_B` が右側にあれば厳しめ（Severity が高い）、左側なら甘めです。`Threshold` 行の区間が大きく重なる場合、カテゴリ境界が曖昧である可能性があり、レベル記述の見直しが必要かもしれません。
- **Posterior Ridgeline Comparison**: 各ファセット全体の分布を比較できます。山が広がっているほど、そのファセット内で差が大きいことを示します。例えば評価者のリッジラインが広い場合は、厳しさにばらつきがあり研修を検討します。課題のリッジラインが狭ければ、難易度が揃っていて受験者を弁別できていないサインです。
- **Threshold Table / Map**: 閾値の平均位置と間隔 (`Spacing`) を一覧にしたものです。Spacing が均等ならカテゴリの段差が揃っています。例えば T2 と T3 の Spacing が極端に短いなら、カテゴリ 3 と 4 がほぼ同じ意味になっている可能性があり、ルーブリックの再設計を検討します。
- **Category Probability Curves**: 能力値に応じて各カテゴリを選ぶ確率を描いたものです。山の頂点が階段状に右へずれていれば、カテゴリが順序通りに機能しています。例えば、能力 0 付近でカテゴリ 2 の確率が最も高く、能力 2 付近でカテゴリ 4 の確率が高いなら、能力が上がるにつれて上位カテゴリに移行できていると解釈できます。もしカテゴリ 2 と 3 の曲線がほぼ重なっていれば、両者を区別する指標が弱いかもしれません。`Flexible` モデルでは各曲線の重なり具合から閾値の自然な位置を確認でき、`Equidistant` では曲線がほぼ均等な幅で入れ替わるはずです。

確率曲線は閾値の設定と密接に関連しています。例えば `Threshold` T2 と T3 の間隔が狭すぎると、カテゴリ 3 の山が低く広がり、どの能力値でもカテゴリ 3 を選ぶ確率が低くなります。その場合はカテゴリ記述の調整や、等間隔モデルでの再推定が有効です。一方、カテゴリ 4 の山が右端まで伸びきっていれば、上位能力層のデータが不足している可能性があり、タスク難易度を上げるなどの改善を検討します。

これらの可視化を合わせて見ることで、例えば「評価者の厳しさが受験者より高すぎて高得点が出ない」「カテゴリ 4 と 5 の境界がほぼ同じ位置にあり、最上位評価が使われていない」といった課題をすばやく把握できます。必要に応じて、課題の難易度調整、評価者研修、カテゴリ定義の再設計などを検討してください。

`Thresholds` タブは Step 4 の閾値構造と `Fixed Effects` の閾値テーブルと密接に関係します。`Fixed Effects` で表示される閾値は、カテゴリ 1↔2、2↔3 といった境界の事後平均で、ここでは同じ値を別形式で確認できます。

- **Flexible を選んだ場合**: 各閾値が完全に自由に推定されます。`Spacing` 列に表示される間隔が不均一でも問題なく、カテゴリ間の距離がデータに合わせて調整されます。例：`Spacing` が「3.8 → 3.7 → NA」と大きく異なる場合、最初の境界と次の境界は異なる難しさを持つことを意味します。Wright Map や確率曲線で確認し、意図した評価の段差になっているか判断します。
- **Equidistant を選んだ場合**: モデルの内部で閾値が等間隔になるよう制約がかかります。そのため `Spacing` はほぼ一定になり、確率曲線の山もきれいに階段状に広がります。もし実際の `Spacing` や確率曲線が大きくズレるなら、等間隔という仮定が合っていないサインです。
- **Symmetric** は中央を挟んで対称になるよう制約がかかります。カテゴリの中心を基準に「±同じ距離」で閾値が置かれるため、極端なカテゴリの利用状況を整えたいときに有効です。

実務では、まず `Flexible` で実際の閾値のばらつきを把握し、必要なら `Equidistant` や `Symmetric` に切り替えてモデルを再推定し、結果と比較すると良いでしょう。`Threshold Map` と `Category Probability Curves` を組み合わせれば、例えば「Flexible ではカテゴリ 3 と 4 の境界が狭すぎるが、Equidistant にすると適切な間隔になる」といった違いを視覚的に確認できます。
